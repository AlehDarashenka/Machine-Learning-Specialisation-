{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Финальный проект. Неделя 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords as nltk_stop_words\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "чтение тренировочного и тестового датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('products_sentiment_train.tsv', sep = '\\t', header = None)\n",
    "train_data.columns = ('text','label')\n",
    "test_data = pd.read_csv('products_sentiment_test.tsv', sep = '\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 . take around 10,000 640x480 pictures .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the wrt54g plus the hga7t is a perfect solutio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont especially like how music files are uns...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was using the cheapie pail ... and it worked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0          2 . take around 10,000 640x480 pictures .      1\n",
       "1  i downloaded a trial version of computer assoc...      1\n",
       "2  the wrt54g plus the hga7t is a perfect solutio...      1\n",
       "3  i dont especially like how music files are uns...      0\n",
       "4  i was using the cheapie pail ... and it worked...      1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем несколько экспериментов, попробовав несколько классификаторов и разные способы построения словарей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словари с различными параметрами, которые будем перебирать для настройки модели в экспериментах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect_parameters = {'vect__ngram_range':((1,1), (1,2), (1,3)),\n",
    "              'vect__stop_words':('english',nltk_stop_words.words('english'), None),\n",
    "              'vect__min_df':(0, 1),\n",
    "              'vect__max_df':(0.7, 0.8, 0.9)             \n",
    "             }\n",
    "logreg_parameters = {'logreg__penalty': ('l1', 'l2'),\n",
    "                     'logreg__C': (0.001, 0.2, 0.8, 1.0),\n",
    "                     \n",
    "    \n",
    "}\n",
    "linearSVC_parameters = {\n",
    "                        'linearSVC__loss':('hinge','squared_hinge'),\n",
    "                        'linearSVC__C':(0.0001,0.3, 0.5,0.7,1.0)\n",
    "                        \n",
    "    \n",
    "}\n",
    "SGD_parameters = {'sgd__loss':('hinge','squared_hinge'),\n",
    "    #'sgd__loss':('hinge','log', 'modified_huber', 'squared_hinge', 'perceptron'),\n",
    "                  'sgd__penalty':('l1', 'l2'),\n",
    "                  'sgd__epsilon':(0.1,0.01),\n",
    "                  'sgd__n_iter':(5,15, 20)\n",
    "    \n",
    "}\n",
    "tfidf_parameters = {#'tfidf__stop_words':('english',nltk_stop_words.words('english'), None),\n",
    "                    #'tfidf__ngram_range':((1,1), (1,2), (1,3), (3,5)),\n",
    "                    'tfidf__ngram_range':((1,3), (1,4), (2,4)),\n",
    "                    #'tfidf__min_df':(1, 5,8,10),\n",
    "                    'tfidf__max_df':(0.7, 0.8, 0.9),\n",
    "                    'tfidf__norm':('l1','l2')\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#функция которая возвращает лучшую модель, после перебора по сетке\n",
    "def experiment(name, pipeline, dict_params, model_params):\n",
    "    print name, ':'\n",
    "    params = dict_params.copy()\n",
    "    params.update(model_params)\n",
    "    optimizer = GridSearchCV(pipeline,params, scoring='accuracy')\n",
    "    optimizer.fit(train_data['text'], train_data['label'])\n",
    "    print optimizer.best_score_\n",
    "    print optimizer.best_params_\n",
    "    print optimizer\n",
    "    return optimizer.best_estimator_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. CountVectorizer + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('vect', CountVectorizer()), ('logreg', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer + LogisticRegression :\n",
      "0.774\n",
      "{'vect__ngram_range': (1, 1), 'vect__max_df': 0.7, 'logreg__penalty': 'l2', 'logreg__C': 1.0, 'vect__min_df': 0, 'vect__stop_words': None}\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator1 = experiment('CountVectorizer + LogisticRegression', pipeline, vect_parameters, logreg_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. CountVectorizer + LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline1 = Pipeline(steps=[('vect', CountVectorizer()), ('linearSVC', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer + LinearSVC :\n",
      "0.765\n",
      "{'linearSVC__C': 0.3, 'vect__ngram_range': (1, 1), 'vect__max_df': 0.7, 'vect__min_df': 0, 'vect__stop_words': None, 'linearSVC__loss': 'squared_hinge'}\n",
      "Wall time: 3min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator2 = experiment('CountVectorizer + LinearSVC', pipeline1, vect_parameters, linearSVC_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. CountVectorizer +SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline(steps=[('vect', CountVectorizer()), ('sgd', SGDClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer +SGDClassifier :\n",
      "0.779\n",
      "{'vect__ngram_range': (1, 3), 'vect__max_df': 0.8, 'sgd__loss': 'log', 'sgd__penalty': 'l2', 'sgd__epsilon': 0.1, 'vect__min_df': 1, 'vect__stop_words': None, 'sgd__n_iter': 10}\n",
      "Wall time: 38min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "estimator3 = experiment('CountVectorizer +SGDClassifier', pipeline2, vect_parameters, SGD_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4. TFIdfVectorizer + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline3 = Pipeline(steps=[('tfidf', TfidfVectorizer()), ('logreg', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIdfVectorizer +LogisticRegression :\n",
      "0.7575\n",
      "{'tfidf__ngram_range': (1, 1), 'logreg__penalty': 'l2', 'tfidf__stop_words': None, 'tfidf__max_df': 0.7, 'logreg__C': 1.0, 'tfidf__norm': 'l2'}\n",
      "Wall time: 4min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "estimator4 = experiment('TFIdfVectorizer +LogisticRegression', pipeline3, tfidf_parameters, logreg_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    5. TFIdfVectorizer + LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline4 = Pipeline(steps=[('tfidf', TfidfVectorizer()),('linearSVC', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIdfVectorizer+LinearSVC :\n",
      "0.7845\n",
      "{'linearSVC__C': 1.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__max_df': 0.7, 'tfidf__norm': 'l2', 'linearSVC__loss': 'hinge'}\n",
      "Wall time: 5min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator5 = experiment('TFIdfVectorizer+LinearSVC', pipeline4, tfidf_parameters, linearSVC_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    6. TFIdfVectorizer + SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline5 = Pipeline(steps=[('tfidf', TfidfVectorizer()),('sgd', SGDClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIdfVectorizer+SGDClassifier :\n",
      "0.791\n",
      "{'tfidf__ngram_range': (1, 3), 'sgd__loss': 'hinge', 'sgd__penalty': 'l2', 'tfidf__max_df': 0.8, 'sgd__epsilon': 0.01, 'tfidf__norm': 'l2', 'sgd__n_iter': 15}\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Pipeline(steps=[('tfidf', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=Tru...   penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False))]),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'tfidf__max_df': (0.7, 0.8, 0.9), 'sgd__epsilon': (0.1, 0.01), 'tfidf__norm': ('l1', 'l2'), 'tfidf__ngram_range': ((1, 3), (1, 4), (2, 4)), 'sgd__loss': ('hinge', 'squared_hinge'), 'sgd__penalty': ('l1', 'l2'), 'sgd__n_iter': (5, 15, 20)},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring='accuracy', verbose=0)\n",
      "Wall time: 8min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator6 = experiment('TFIdfVectorizer+SGDClassifier', pipeline5, tfidf_parameters, SGD_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: была проведена серия экспериментов, по итогу которых лучшей оказалась модель TF-IDF + SGDClassifier. Эта модель и была выбрана для отправки результатов предсказаний на Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimator6.fit(train_data['text'], train_data['label'])\n",
    "pred = estimator6.predict(test_data['text'])\n",
    "predictions_df = pd.DataFrame(data=pred, columns=['y'])\n",
    "predictions_df.to_csv('predictions.csv', index_label='Id')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
